# ChatGPT API 开发第一步，验证你的 SECRET KEY 能不能用

目录
[TOC]

在取到 ChatGPT 的试用权限之后，便可以着手研究它的 API 了。（具体如何申请，网上有帖子，可以自行谷歌一下。）

对于还没有申请 API 试用权限的读者朋友，抓紧时间在下面这个地址申请：

https://platform.openai.com/

打开后， 如果是第一次登录该平台，可能会有一个让你加入等待列表的提示，按提示操作。通过后，会有一封邮件给你。

## 生成接口调用密钥

首先，在下面这个网址：

https://platform.openai.com/account/api-keys

点击“Create new secret key”按钮，便可以生成一个 SECRET KEY，这个东西只展示一次，生成后立马拷贝至一个外人看不到的地方保存起来。

SECRET KEY 我们可以称之为接口调用密钥，当我们稍后调用 ChatGPT 的每一个 API 时，都需要将这个密钥带上，ChatGPT 靠它知道我们是谁，并从我们的帐号中扣钱。

有人可能会问，这个 SECRET KEY 我不申请行不行，我用别人的？

当然可以，只要别人让人用。所以刚才我们讲，在你生成这个密钥之后，一定要把它放在一个别人看不到的地方。有人会错把它放在 Github 仓库里，这是一种失误，如果真出现了泄漏，也不要紧张，还是在上面的生成页面，单击密钥后面的删除按钮，将它删除便是了。

![image-20230325200833162](https://cdn.jsdelivr.net/gh/rixingyike/images@master/2023/202303252008321.png)

## 关于费用问题

刚才我们说了，接口调用是要花钱的。但 ChatGPT 为了方便开发者上手，为每人提供了一个小数额的信用额度，这个额度从早期的 $20，到后来的 $18，再到目前的\$5，信用额度是越来越低了。

这可能与使用的开发者过多及资源有限有关，所以我奉劝想研究 ChatGPT 的开发者，有时间尽早去发邮件申请一下 API 的试用权限。哪怕申请了之后你不用，额度也一直在哪里，在截止目前之前不会减少。

你可以在下面这个链接查看你剩余的额度：

![image-20230325201629181](https://cdn.jsdelivr.net/gh/rixingyike/images@master/2023/202303252016277.png)

如果初始信用额度用完了，你可以在下面这个地址设置你的信用卡，每月月底 ChatGPT 会从你的卡上扣钱。

https://platform.openai.com/account/billing/overview

## 使用 curl 测试 API 通否

拿到密钥以后，第一步是测试接口的连通问题，这是最简单的，但也是最重要的。接口链路不通，后面一切都得研究了。

假设你的电脑上已经有了终端 curl 工具（没有的话可以自行搜索安装一下），在终端中执行以下代码：

```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

99.99%的概率你看不到正确的返回。在这里有两个问题需要我们先处理一下。

第一个，关于系统变量\$OPENAI_API_KEY，它是需要我们手动设置的。在 Windows 机器上，我们需要在系统设置->环境变量里面，添加名称为 OPENAI_API_KEY 的变量，值就是上面我们刚刚生成的 API 密钥。如果是 macOS/Linux 系统，我们需要在 bash 配置文件中手动导出一个名称为 OPENAI_API_KEY 的变量，值同样也是 API 密钥。

具体设置方法如果有不明白的可以谷歌。验证环境变量设置是否成功，可以在终端里执行以下指令：

```bash
echo $OPENAI_API_KEY
```

第二个，就是调用请求从我们的电路上发出，至到达终点，中间可能会遇到高墙大山，这时候我们需要梯子。研究 ChatGPT API 开发，梯子就像电工的钳子一样，必须随身携带。

将本地梯子设置好以后，在 curl 指令参数列表中加上 proxy 参数，如下所示：

```bash
curl --proxy http://127.0.0.1:7890 https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

如果前面的两步你都完成了，正常情况下你就能得到一个 Models List 文本。ChatGPT 有很多模型，/v1/models 这个接口就是返回我们可以选择的模型，每个模型的功能、处理能力及价格都是不一样的，在目前我们知道这一点就足够了（应该足够了）。

返回的结果很长，是一个 JSON 字符串，内容没有必要细看，意义不大。我通过 map 方法处理了一下这个结果：

```js
let models = ret.data.map(item=>item.id)
```

最后得到的列表是这样的：

```text
(62) ['babbage', 'davinci', 'babbage-code-search-code', 'text-similarity-babbage-001', 'text-davinci-001', 'ada', 'curie-instruct-beta', 'babbage-code-search-text', 'babbage-similarity', 'whisper-1', 'code-search-babbage-text-001', 'text-curie-001', 'code-search-babbage-code-001', 'text-ada-001', 'text-embedding-ada-002', 'text-similarity-ada-001', 'ada-code-search-code', 'ada-similarity', 'text-davinci-003', 'code-search-ada-text-001', 'text-search-ada-query-001', 'davinci-search-document', 'ada-code-search-text', 'text-search-ada-doc-001', 'davinci-instruct-beta', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-search-query', 'gpt-3.5-turbo-0301', 'davinci-search-query', 'babbage-search-document', 'ada-search-document', 'text-search-curie-query-001', 'text-search-babbage-doc-001', 'gpt-3.5-turbo', 'curie-search-document', 'text-search-curie-doc-001', 'babbage-search-query', 'text-babbage-001', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'curie-similarity', 'curie', 'text-similarity-davinci-001', 'text-davinci-002', 'davinci-similarity', 'cushman:2020-05-03', 'ada:2020-05-03', 'babbage:2020-05-03', 'curie:2020-05-03', 'davinci:2020-05-03', 'if-davinci-v2', 'if-curie-v2', 'if-davinci:3.0.0', 'davinci-if:3.0.0', 'davinci-instruct-beta:2.0.0', 'text-ada:001', 'text-davinci:001', 'text-curie:001', 'text-babbage:001']
```

## 最佳的模型选择

一共有 62 个，这是理论上我们在使用 ChatGPT 的能力时，可以选择的模型。有很多模型可能我们一直都不会研究，有 5 个模型是我们接下来可能会经常用到的。它们是：

- Ada 阿达
- Bargage 巴贝奇
- Curie 居里
- Davinci 达芬奇
- gpt-3.5-turbo 3.5 涡轮

这 5 个模型，它们的能力从上至下是逐步升高的，它们的处理速度整体上（至少在前 4 个里面）是逐步降低的，这也很好理解，任务越复杂越要耗费的 CPU 时间就越多。还有，它们的每一千个 token（什么是 token？）消耗的 money（在前 4 个里面）也是逐步升高的，这可以理解为，能力越大，成本越大。

这里提到了一个新概念：token，什么是 token？这是个程序里的概念，可以简单理解为汉语里的字，英语句子里的单词，甚至单词里包含的前缀、后缀。有人做过统计，大概每 750 个字相当于 1000 个 token。token 是 ChatGPT API 接口调用的计量单位。

这 5 个模型我们看到了，基本越往后能力越大，但耗时及资费也越来越贵。但第 5 个模型 gpt-3.5-turbo，目前是一个例外。除了 GPT-4 的 API 之外，它在目前 5 个模型中，能力是最强的。我们看一下它们的资费对比：

- Ada \$0.0004
- Babbage \$0.0005
- Curie \$0.002
- Davinci \$0.02
- gpt-3.5-turbo \$0.002

gpt-3.5-turbo 不是最贵的，也不是处理时间最快的，但综合考虑能力、资费及耗时，它是目前的最优选择。除非你的工作任务使用前几个模型就可以完成，否则使用 gpt-3.5-turbo 模型是毫无疑问的默认选项。

好，现在知道选择哪个选型了。我们测试一两个 API，分别用 Node.js 和 Python 两种语言。

## 使用 Node.js 验证基于提示的问答接口

下面我们用 Node.js，实现对 ChatGPT 问答接口的调用。基于提示指令的问答，是 ChatGPT 最常被使用的接口。直接上主要代码吧：

```javascript
// disc/01/main.js
import httpsProxyAgent from "https-proxy-agent";
import env from "env";

// all_proxy=socks5://127.0.0.1:7890
function httpsAgent() {
	// @ts-ignore
	return new httpsProxyAgent( {
		host: '127.0.0.1',
		port: 7890,
		protocol: 'socks5'
	} );
}

async function test(messages) {
  const apiKey = env.getenv("OPENAI_API_KEY");
  const result = await fetch(`https://api.openai.com/v1/chat/completions`, {
    agent: httpsAgent(),
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    method: "POST",
    body: JSON.stringify({
      messages,
      model: "gpt-3.5-turbo",
      temperature: 0.5,
      max_tokens: 4096,
      stream: true,
    })
  });
  return result
}

async function main() {
  const r = await test("What's your name?").catch(console.log);
  console.log("result：",r);
}

main();
```

解释一下这个示例吧：

- 第 1 行，https-proxy-agent 是一个第三方模块，是用来设置本地代理的，需要提前安装；
- 第 8 行至第 12 行，这里设置的是本地代理，在测试开始之前，一定要记得开启代理；
- 第 16 行，这里是从环境变量中取密钥，这一步依赖前面使用 curl 测试 API 的一步。这里就体现了使用环境变量的好处，密钥放在本地电脑里面，不会随代码被推到 Github 仓库里；
- 第 17 行，这个地址/v1/chat/completions 就是问答的 API 地址；
- 第 26 行，这里选择的模型是 gpt-3.5-turbo，这是前面我们选定的默认模型。

在测试之前，有一点可能需要说明一下，这是一个 Node.js 项目，位置位于 disc/01，在测试时它需要被当作一个 Node.js 项目启动，测试指令为：

```bash
yarn dev or npm run dev
```

如果你不这样做，而直接执行 node main.js，可能会遇到一个关于 Node.js 模块导入的语法错误。

所有步骤一切都搞定以后，执行测试，应该就能看到结果了。

## 使用 Python 测试接口

前面使用 Node.js 测试接口，每一个接口参数都需要我们自己传递，这对于一部分开发者来说可能是透明的优点，但对于另外一部分开发者来说，可能就是麻烦了。下面我们尝试使用官方封装的 openai 模块，在 Python 中调用官方的 API。

首先，是安装 openai 模块：

```bash
pip3 install openai
```

在 Node.js 中，其实也有一个现成的 openai 模块，它可以使用 yarn 或 npn 安装：

```
yarn add openai or npm install openai
```

如果你想简单一些，又使用 Node.js 进行开发，可以安装这个 openai 模块。

### 获取 models 列表

下面的 Py 代码用于拉取 models：

```python
# disc/02.py
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")
print(openai.Model.list())
```

它在内部也是调用了/v1/models 接口，只是封装了起来，只需要我们提供一个必须提供的 api_key。

### 调用 Chat 聊天接口

调用的是聊天接口/v1/chat/completions，代码如下所示：

```python
# disc/03.py
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

completion = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[{"role": "user", "content": "Do u know yishulun？"}]
)

print(completion)
```

对于像这样的简单的 Py 代码，可以这样测试：

```python
python3 03.py
```

### 调用 Completion 问答接口

将要调用的是/v1/completions 接口，它在前面使用过，基于开发者提供的指令（prompt），完成特定的任务：

```python
# disc/04.py
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")
text_prompt = "请你扮演一个脱口秀演员，讲一个与‘艺述论’有关的笑话。"
completion = openai.Completion.create(
    model="text-davinci-003",
    prompt=text_prompt,
    temperature=0.5,
)

generated_text = completion.choices[0].text
print(generated_text)
```

在这里有一个问题，请注意，**如果我们将第 8 行的模型换成 gpt-3.5-turbo，对不起代码就报错了，为什么？**

### 由文本生成图片

怎么生成呢？直接上 Py 代码吧：

```python
# disc/05/main.py
import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
response = openai.Image.create(
  prompt="A red fish bites a black dog.",
  n=2,
  size="1024x1024"
)
# ['256x256', '512x512', '1024x1024']
image_url = response['data']
print(image_url)
```

这个示例会返回两个图片，其中一张是这样的：

![img1](https://cdn.jsdelivr.net/gh/rixingyike/images@master/2023/202303252146359.png)

第 8 行传递的参数 size，只能从有限的备选项中选取，它们是['256x256', '512x512', '1024x1024'] 。注意，**这里的 size 为什么一定是正方形呢？为什么不能由开发者随便指定比例及大小呢？**

## 小结

基本上通过以上几步的折腾，你大概就能搞明白 ChatGPT API 怎么调用了。当然了，具体的每个接口如何使用，还需要看官方的文档，地址是：

https://platform.openai.com/docs/api-reference

这篇文章的主要意义，在于使用 Node.js、Python 这样简单的脚本语言，快速验证你的密钥是否可用，是否具备进行 ChatGPT API 研究的基础条件。

有问题欢迎在评论区提问。
